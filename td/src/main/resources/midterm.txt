1. Pseudocode for algorithms to generate the graphs
2. How do I generate the training sets?
3. By the TD delta update rule:
dwt = alpha*(Pt+1 - Pt)*sum(x1+x2+...+xt)
Q: how can we look in the future Pt+1 to compute dwt?
We can only compute w after the end of the sequence, after we know all results!
Even though the pdf says we can!
4. How to represent vectors: use apache commons math classes
5. SL vs TD: which one approaches best the w(ideal)=[1/6,2/6,3/6,4/6,5/6] array?
6. The alg to generate first graph is the following:
init w randomly (according to theorem, this alg always converges)
repeat
 for each TS(i)
   delta-w = 0
   for each Seq(j)
   	compute delta-w(Seq(j), alpha, lambda) -> the change of w for each observation according to alpha, lambda
   delta-w += delta-w(Seq(j), alpha, lambda)
   w += delta-w	
until changes in w are smaller than epsilon
computeRMS(w-ideal, w)
7. Figure 3: what does it mean "average over the training sets"?
8. When should I exit in RepeatedPresentation?
After all training sets or after each training set (should I compute almostSame())?
9. It is amazing that regardless of the init of w, the RMS is always the same for the same <alpha, lambda>!

10. Memorie: 2 numere, nu n

11. !!! using a high alpha = 0.1, the formula does not convergence! It is exactly like ML, where the gradient just goes by the local min and 
increases from that point on!

12. !!! use a training set with less/more sequences in it and see the error on those!

13. !!! from alpha=0.01, the alg coverges n average on 100 iterations, with an error of 0.022, whereas 
from alpha=0.001, the alg converges on average on 700 iterations (so slower) with a lower error 0.013!
Why?!?!

14. !!! with alpha=0 (deltaW=0, so no learning), the error obtained is actually 0.52, converges
in just 1 iteration; this error 0.52 is higher than 0.19 from paper, so I believe the paper is quite wrong!

15. Init w with ideal values! 